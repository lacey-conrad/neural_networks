{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab49a3b2",
   "metadata": {},
   "source": [
    "# Calculating metrics from pytorch NN output for categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8779ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import our library\n",
    "import torchmetrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a8611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = torchmetrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16145d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on batch 0: 0.10000000149011612\n",
      "Accuracy on batch 1: 0.10000000149011612\n",
      "Accuracy on batch 2: 0.20000000298023224\n",
      "Accuracy on batch 3: 0.20000000298023224\n",
      "Accuracy on batch 4: 0.5\n",
      "Accuracy on batch 5: 0.20000000298023224\n",
      "Accuracy on batch 6: 0.10000000149011612\n",
      "Accuracy on batch 7: 0.20000000298023224\n",
      "Accuracy on batch 8: 0.30000001192092896\n",
      "Accuracy on batch 9: 0.20000000298023224\n",
      "Accuracy on all data: 0.20999999344348907\n"
     ]
    }
   ],
   "source": [
    "n_batches = 10\n",
    "for i in range(n_batches):\n",
    "    # simulate a classification problem\n",
    "    preds = torch.randn(10, 5).softmax(dim=-1)\n",
    "    target = torch.randint(5, (10,))\n",
    "\n",
    "    # metric on current batch\n",
    "    acc = metric(preds, target)\n",
    "    print(f\"Accuracy on batch {i}: {acc}\")    \n",
    "\n",
    "# metric on all batches using custom accumulation\n",
    "acc = metric.compute()\n",
    "print(f\"Accuracy on all data: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b103ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1605, 0.3604, 0.1251, 0.2884, 0.0656],\n",
       "        [0.3127, 0.0379, 0.2730, 0.2690, 0.1075],\n",
       "        [0.3782, 0.1159, 0.2667, 0.2001, 0.0391],\n",
       "        [0.1932, 0.4260, 0.1140, 0.0272, 0.2396],\n",
       "        [0.0190, 0.0523, 0.2298, 0.2617, 0.4371],\n",
       "        [0.4058, 0.1006, 0.1238, 0.1337, 0.2360],\n",
       "        [0.0565, 0.2157, 0.0974, 0.3100, 0.3204],\n",
       "        [0.5165, 0.0437, 0.2613, 0.0946, 0.0839],\n",
       "        [0.2227, 0.3970, 0.1039, 0.0879, 0.1885],\n",
       "        [0.0611, 0.0175, 0.5535, 0.2605, 0.1075]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461fb041",
   "metadata": {},
   "source": [
    "### Input:  \n",
    "1. predicted values from NN and \n",
    "2. actual values/labels.\n",
    "\n",
    "You will want to be able to see if a predicted value is the same as the actual value. i.e.  \n",
    "predicted == actual.squeeze (1)). sum () calculates the number of all instances where the predicted value is the same as the actual value.\n",
    "\n",
    "### Potential output: \n",
    "accuracy, precision, recall, TP, TN, FP, FN, IoU, etc.\n",
    "\n",
    "## Note: double check datatypes.  Use the int() method to convert torch objects to ints.\n",
    "\n",
    "### Adapted from: \n",
    "https://www.tutorialfor.com/blog-282508.htm\n",
    "\n",
    "https://en.wikipedia.org/wiki/Sensitivity_and_specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db5308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47141d58",
   "metadata": {},
   "source": [
    "| Key ||\n",
    "|:--|:--|\n",
    "|P |positive instances of a condition |\n",
    "|N |negative instances of a condition|\n",
    "|TP |true positive|\n",
    "|TN |true negative|\n",
    "|FP |false positive|\n",
    "|FN |false negative|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89045c5",
   "metadata": {},
   "source": [
    "|total pop = P+N|Predicted condition positive (PP)|Predicted condition negative (PN)|\n",
    "|:--|:-:|:-:|\n",
    "|Actual condition positive (P)|TP (= hit) |FN (Type II error)  Underestimation|\n",
    "|Actual condition positive (N)|FP (Type I error) Overestimation |TN (= correct rejection)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26e042aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = preds.numpy()\n",
    "actual = target.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e68a665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34896025, 0.24110317, 0.06090532, 0.1837537 , 0.16527757],\n",
       "       [0.04727532, 0.12720998, 0.6532213 , 0.03946552, 0.1328279 ],\n",
       "       [0.07913141, 0.25618678, 0.16246547, 0.34483114, 0.15738522],\n",
       "       [0.01374449, 0.23489994, 0.02236762, 0.6424571 , 0.08653083],\n",
       "       [0.17110842, 0.28075624, 0.16399515, 0.03512565, 0.34901458],\n",
       "       [0.13203181, 0.3357053 , 0.25312364, 0.16717713, 0.11196211],\n",
       "       [0.17804138, 0.42529374, 0.15184651, 0.09479353, 0.15002483],\n",
       "       [0.20513968, 0.06917416, 0.04350902, 0.43064734, 0.25152978],\n",
       "       [0.28718507, 0.03871686, 0.16038804, 0.07408937, 0.43962067],\n",
       "       [0.05545131, 0.28975555, 0.13945523, 0.12559803, 0.38973993]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e605a71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True, False, False,  True, False,  True, False, False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes = torch.argmax(preds, dim=1) == 0\n",
    "predicted_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36707c14",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52af381",
   "metadata": {},
   "source": [
    "accuracy = tp+tn/(p+n) = tp+tn/(tp+tn+fp+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90c13bf",
   "metadata": {},
   "source": [
    "Basically, you can find the number of values where predicted == actual, add them up, and divide by the number in the dataset (i.e. training dataset...it needs to be specific to what dataset you are working with).  It is essentially an average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62298812",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot select an axis to squeeze out which has size not equal to one",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-38d514896471>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# total number of correct predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Used to calculate the accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#train_acc += train_correct.data [0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot select an axis to squeeze out which has size not equal to one"
     ]
    }
   ],
   "source": [
    "# total number of correct predictions\n",
    "train_correct = (predicted == actual.squeeze(1)).sum()\n",
    "\n",
    "#Used to calculate the accuracy\n",
    "#train_acc += train_correct.data [0]\n",
    "\n",
    "#Accuracy:\n",
    "#train_acc/(len (train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc12e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    ".squeeze (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca8ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd8b8eaa",
   "metadata": {},
   "source": [
    "# At this point, double check datatypes.  Use the int() method to convert torch objects to ints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0802dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode, assumes 1 = pos, 0 = false for pred == actual\n",
    "\n",
    "# All 0 variables\n",
    "# torch.zeros Returns a tensor filled with the scalar value 0, with the shape defined by \n",
    "# the variable argument size.\n",
    "zeros = variable(torch.zeros(lasize).type (torch.longtensor)) \n",
    "\n",
    "#All 1 variables\n",
    "ones = variable (torch.ones (lasize) .type (torch.longtensor)) \n",
    "\n",
    "#The total number of original labels is 1, and the prediction is 0\n",
    "train_correct01 = ((pred == zeros) & (batch_y.squeeze (1) == ons)). sum () \n",
    "\n",
    "#The total number of original labels is 0 and the prediction is 1.\n",
    "train_correct10 = ((pred == ones) & (batch_y.squeeze (1) == zes)). sum () \n",
    "\n",
    "# true pos\n",
    "train_correct11 = ((pred_y == ones) & (batch_y.squeeze (1) == ons)). sum ()\n",
    "\n",
    "# true neg\n",
    "train_correct00 = ((pred_y == zeros)&(batch_y.squeeze (1) == zes)). sum ()\n",
    "\n",
    "# total number of incorrect predictions in the training set:\n",
    "\n",
    "# false neg\n",
    "fn += train_correct01.data [0]\n",
    "\n",
    "# false pos\n",
    "fp += train_correct10.data [0]\n",
    "\n",
    "# true pos\n",
    "tp += train_correct11.data [0]\n",
    "\n",
    "# true neg\n",
    "tn += train_correct00.data [0]\n",
    "\n",
    "# False positive rate:\n",
    "# ctw + wtc\n",
    "(fn + fp)/(len (train_data)) \n",
    "\n",
    "# Accuracy and recall\n",
    "#Accuracy\n",
    "p = tp/(tp + fp)\n",
    "\n",
    "#Recall rate\n",
    "r = tp/(tp + fn)\n",
    "\n",
    "# Real and false positive rates\n",
    "\n",
    "#True rate:\n",
    "tpr = tp/(tp + fn)\n",
    "\n",
    "#False positive rate:\n",
    "fpr = fp/(fp + tn)\n",
    "\n",
    "#IoU\n",
    "iou = tp / (tp + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88527a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
